{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29b1943",
   "metadata": {},
   "source": [
    "## BioVid HeatPain — Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b59dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import display\n",
    "from typing import Optional, Dict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('/content/drive/MyDrive/PainRecognitionProject/data/BioVid_HeatPain/')\n",
    "SOURCE_CSV_FILENAME = 'samples.csv'\n",
    "SOURCE_CSV_PATH = BASE_DIR / SOURCE_CSV_FILENAME\n",
    "\n",
    "print(f\"Source CSV: {SOURCE_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15613c8a",
   "metadata": {},
   "source": [
    "### Base folder check - BioVid_HeatPain folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_integrity(\n",
    "    base_dir: str,\n",
    "    expected_files_per_subject: int = 100,\n",
    "    prefix_sep: str = '-',\n",
    "    allowed_exts: tuple = ('.mp4',),\n",
    "    sample_csv_path: Optional[str] = None,\n",
    "    max_examples: int = 3,\n",
    "    save_report_path: Optional[str] = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scan `base_dir` subject subfolders and return integrity report.\n",
    "    If `sample_csv_path` given, cross-check listed samples against actual files.\n",
    "    \"\"\"\n",
    "    base = Path(base_dir)\n",
    "    if not base.is_dir():\n",
    "        raise FileNotFoundError(f\"Base directory does not exist: {base_dir}\")\n",
    "\n",
    "    subject_folders = [p for p in base.iterdir() if p.is_dir()]\n",
    "    report = {\n",
    "        'base_dir': str(base.resolve()),\n",
    "        'n_subjects': len(subject_folders),\n",
    "        'total_mp4_files': 0,\n",
    "        'folders_wrong_count': {},\n",
    "        'naming_issues': {},\n",
    "        'duplicates': {},\n",
    "        'unexpected_extensions': {},\n",
    "        'missing_samples': {},\n",
    "    }\n",
    "\n",
    "    samples_df = None\n",
    "    if sample_csv_path:\n",
    "        samples_df = pd.read_csv(sample_csv_path)\n",
    "        samples_df_columns = set(samples_df.columns)\n",
    "\n",
    "    for subject in sorted(subject_folders):\n",
    "        mp4_files = [f.name for f in subject.iterdir() if f.is_file() and f.suffix.lower() in allowed_exts]\n",
    "        other_files = [f.name for f in subject.iterdir() if f.is_file() and f.suffix.lower() not in allowed_exts]\n",
    "        report['total_mp4_files'] += len(mp4_files)\n",
    "\n",
    "        if len(mp4_files) != expected_files_per_subject:\n",
    "            report['folders_wrong_count'][subject.name] = len(mp4_files)\n",
    "\n",
    "        bad_names = [fn for fn in mp4_files if not fn.startswith(f\"{subject.name}{prefix_sep}\")]\n",
    "        if bad_names:\n",
    "            report['naming_issues'][subject.name] = bad_names[:max_examples]\n",
    "\n",
    "        seen = set()\n",
    "        dups = []\n",
    "        for fn in mp4_files:\n",
    "            if fn in seen:\n",
    "                dups.append(fn)\n",
    "            else:\n",
    "                seen.add(fn)\n",
    "        if dups:\n",
    "            report['duplicates'][subject.name] = dups\n",
    "\n",
    "        if other_files:\n",
    "            report['unexpected_extensions'][subject.name] = other_files[:max_examples]\n",
    "\n",
    "        if samples_df is not None:\n",
    "            if 'video_path' in samples_df.columns:\n",
    "                expected_for_subject = samples_df[samples_df['video_path'].str.startswith(subject.name + '/')]\n",
    "                expected_files = expected_for_subject['video_path'].apply(lambda p: os.path.basename(p)).tolist()\n",
    "            elif {'subject_name', 'sample_name'}.issubset(samples_df.columns):\n",
    "                expected_for_subject = samples_df[samples_df['subject_name'] == subject.name]\n",
    "                expected_files = (expected_for_subject['sample_name'] + '.mp4').tolist()\n",
    "            else:\n",
    "                expected_files = []\n",
    "\n",
    "            if expected_files:\n",
    "                missing = [fn for fn in expected_files if fn not in mp4_files]\n",
    "                if missing:\n",
    "                    report['missing_samples'][subject.name] = missing[:max_examples]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Dataset check: {report['n_subjects']} subjects, {report['total_mp4_files']} mp4 files found\")\n",
    "        if report['folders_wrong_count']:\n",
    "            print(f\"Folders with wrong MP4 count: {len(report['folders_wrong_count'])}\")\n",
    "        else:\n",
    "            print(\"All folders have the expected file count (or none deviated).\")\n",
    "\n",
    "        if report['naming_issues']:\n",
    "            print(f\"Naming issues in {len(report['naming_issues'])} folders (examples shown).\")\n",
    "        if report['duplicates']:\n",
    "            print(f\"Duplicates in {len(report['duplicates'])} folders.\")\n",
    "        if report['unexpected_extensions']:\n",
    "            print(f\"Unexpected file extensions in {len(report['unexpected_extensions'])} folders.\")\n",
    "        if samples_df is not None and report['missing_samples']:\n",
    "            print(f\"Missing samples listed in CSV for {len(report['missing_samples'])} folders.\")\n",
    "\n",
    "        def show_examples(d: dict, title: str):\n",
    "            if d:\n",
    "                print(f\"\\n{title}:\")\n",
    "                for subj, vals in list(d.items())[:5]:\n",
    "                    print(f\" - {subj}: {vals if isinstance(vals, list) else vals}\")\n",
    "\n",
    "        show_examples(report['folders_wrong_count'], \"Folders with wrong file counts\")\n",
    "        show_examples(report['naming_issues'], \"Naming issues (examples)\")\n",
    "        show_examples(report['duplicates'], \"Duplicate filenames\")\n",
    "        show_examples(report['unexpected_extensions'], \"Unexpected file extensions\")\n",
    "        if samples_df is not None:\n",
    "            show_examples(report['missing_samples'], \"Missing expected samples from CSV\")\n",
    "\n",
    "    if save_report_path:\n",
    "        out_dir = Path(save_report_path)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        rows = []\n",
    "        for subject in sorted(subject_folders):\n",
    "            rows.append({\n",
    "                'subject': subject.name,\n",
    "                'mp4_count': len([f for f in subject.iterdir() if f.is_file() and f.suffix.lower() in allowed_exts]),\n",
    "                'naming_issues': ';'.join(report['naming_issues'].get(subject.name, [])),\n",
    "                'duplicates': ';'.join(report['duplicates'].get(subject.name, [])),\n",
    "                'unexpected_files': ';'.join(report['unexpected_extensions'].get(subject.name, [])),\n",
    "                'missing_samples': ';'.join(report['missing_samples'].get(subject.name, []))\n",
    "            })\n",
    "        pd.DataFrame(rows).to_csv(out_dir / 'dataset_integrity_by_subject.csv', index=False)\n",
    "        print(f\"\\nReport saved to: {out_dir}\")\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ddfa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = check_dataset_integrity('/content/drive/MyDrive/PainRecognitionProject/data/BioVid_HeatPain/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e46295",
   "metadata": {},
   "source": [
    "### Data division - Training / Validation / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04a008",
   "metadata": {},
   "source": [
    "Subject division proposed by the creators of the database\n",
    "https://www.nit.ovgu.de/nit_media/Bilder/Dokumente/BIOVID_Dokumente/BioVid_HoldOutEval_Proposal.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37608179",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_TEST_SUBJECTS_IDS = [\n",
    "    '100914_m_39', '101114_w_37', '082315_w_60', '083114_w_55', '083109_m_60',\n",
    "    '072514_m_27', '080309_m_29', '112016_m_25', '112310_m_20', '092813_w_24',\n",
    "    '112809_w_23', '112909_w_20', '071313_m_41', '101309_m_48', '101609_m_36',\n",
    "    '091809_w_43', '102214_w_36', '102316_w_50', '112009_w_43', '101814_m_58',\n",
    "    '101908_m_61', '102309_m_61', '112209_m_51', '112610_w_60', '112914_w_51',\n",
    "    '120514_w_56'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_subject_split(df_all_clips, val_test_subjects_ids):\n",
    "    \"\"\"\n",
    "    Split clips into train/validation/test sets based on subject IDs.\n",
    "    Implements a fixed, balanced split where 26 specified subjects are divided into Validation (13) and Test (13).\n",
    "    \"\"\"\n",
    "\n",
    "    temp_data = [{'subject_name': id, 'gender': id.split('_')[1], 'expression': 'Low' if id in ['100914_m_39', '101114_w_37', '082315_w_60', '083114_w_55', '083109_m_60'] else 'Normal'} \n",
    "                 for id in val_test_subjects_ids]\n",
    "    df_26 = pd.DataFrame(temp_data)\n",
    "\n",
    "    # Niska ekspresja (5): Val: 1 M, 1 W; Test: 1 M, 2 W\n",
    "    low_m = df_26[(df_26['expression'] == 'Low') & (df_26['gender'] == 'm')]\n",
    "    low_w = df_26[(df_26['expression'] == 'Low') & (df_26['gender'] == 'w')]\n",
    "    val_low_ids = pd.concat([low_m.iloc[0:1], low_w.iloc[0:1]])['subject_name'].tolist()\n",
    "    test_low_ids = pd.concat([low_m.iloc[1:2], low_w.iloc[1:3]])['subject_name'].tolist()\n",
    "\n",
    "    # Normalna ekspresja (21): Val: 11; Test: 10 (zrównoważony podział reszty)\n",
    "    df_normal = df_26[df_26['expression'] == 'Normal'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val_normal_ids = df_normal.iloc[:11]['subject_name'].tolist()\n",
    "    test_normal_ids = df_normal.iloc[11:]['subject_name'].tolist()\n",
    "\n",
    "    # Finalne listy ID pacjentów\n",
    "    val_ids = val_low_ids + val_normal_ids\n",
    "    test_ids = test_low_ids + test_normal_ids\n",
    "\n",
    "    df_val = df_all_clips[df_all_clips['subject_name'].isin(val_ids)].copy()\n",
    "    df_test = df_all_clips[df_all_clips['subject_name'].isin(test_ids)].copy()\n",
    "    df_train = df_all_clips[~df_all_clips['subject_name'].isin(val_ids + test_ids)].copy()\n",
    "\n",
    "    print(f\"\\n--- Weryfikacja Podziału Pacjentów ---\")\n",
    "    print(f\"Trening (Klipów): {len(df_train)} | Pacjentów: {df_train['subject_name'].nunique()}\")\n",
    "    print(f\"Walidacja (Klipów): {len(df_val)} | Pacjentów: {df_val['subject_name'].nunique()}\")\n",
    "    print(f\"Test (Klipów): {len(df_test)} | Pacjentów: {df_test['subject_name'].nunique()}\")\n",
    "    print(f\"Całkowita liczba pacjentów: {df_all_clips['subject_name'].nunique()}\")\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_master = pd.read_csv(SOURCE_CSV_PATH, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Source CSV not found: {SOURCE_CSV_PATH}\")\n",
    "\n",
    "print(f\"Loaded {len(df_master)} rows; unique subjects: {df_master['subject_name'].nunique()}\")\n",
    "display(df_master.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e917eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['video_path'] = df_master['subject_name'] + '/' + df_master['sample_name'] + '.mp4'\n",
    "df_master['label'] = df_master['class_id']\n",
    "\n",
    "display(df_master[['video_path', 'label']].head())\n",
    "print(\"Label counts:\")\n",
    "print(df_master['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = perform_subject_split(df_master, VAL_TEST_SUBJECTS_IDS)\n",
    "\n",
    "print(\"Clips:\", len(df_train), len(df_val), len(df_test))\n",
    "print(\"Unique subjects:\", df_train['subject_name'].nunique(), df_val['subject_name'].nunique(), df_test['subject_name'].nunique())\n",
    "\n",
    "display(df_train.head())\n",
    "display(df_val.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3700aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "output_columns = ['video_path', 'label']\n",
    "\n",
    "df_train[output_columns].to_csv(BASE_DIR / 'train.csv', index=False)\n",
    "df_val[output_columns].to_csv(BASE_DIR / 'val.csv', index=False)\n",
    "df_test[output_columns].to_csv(BASE_DIR / 'test.csv', index=False)\n",
    "\n",
    "print(\"Saved files:\")\n",
    "print(BASE_DIR / 'train.csv')\n",
    "print(BASE_DIR / 'val.csv')\n",
    "print(BASE_DIR / 'test.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
