{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6702a280",
   "metadata": {},
   "source": [
    "### Bi-LSTM model - binary training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from training_utils.preprocessed_dataset import PreprocessedDataset\n",
    "from training_utils.train import Trainer\n",
    "from training_utils.evaluate import Evaluator\n",
    "from models.Bi_LSTM import SequenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea445120",
   "metadata": {},
   "source": [
    "#### Hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 46\n",
    "NUM_FEATURES = 100\n",
    "NUM_CLASSES = 2\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.00005\n",
    "DROPOUT_PROB = 0.3\n",
    "WEIGHT_DECAY = 0.005\n",
    "SCHEDULER_FACTOR = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9685e7",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_ROOT = '/content/drive/MyDrive/PainRecognitionProject/'\n",
    "PROCESSED_DATA_DIR = os.path.join(COLAB_ROOT, 'data/BioVid_HeatPain_processed_478_xyz_frontalized/')\n",
    "MODEL_SAVE_DIR = os.path.join(COLAB_ROOT, 'models/')\n",
    "LOCAL_PROCESSED_DATA_ROOT = '/content/temp_data/'\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9924987",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.copytree(PROCESSED_DATA_DIR, LOCAL_PROCESSED_DATA_ROOT)\n",
    "    print(\"✅ Kopiowanie zakończone pomyślnie. Czas trwania: (sprawdź zegar)\")\n",
    "    CURRENT_DATA_DIR = LOCAL_PROCESSED_DATA_ROOT\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Błąd kopiowania danych (sprawdź, czy dane są zamontowane): {e}\")\n",
    "    print(\"Używam danych bezpośrednio z Drive (może się zawiesić).\")\n",
    "    CURRENT_DATA_DIR = PROCESSED_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7fa89",
   "metadata": {},
   "source": [
    "tutaj pamietac zeby podac wlasciwa ilosc punktow w zaleznosci ile wspolrzednych uzywamy i czy sa to odleglsoci euklideoswe czy nie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best100 = np.load('/content/drive/MyDrive/PainRecognitionProject/data/top_100_important_landmarks_emotions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70551432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreprocessedDataset(\n",
    "    'train',\n",
    "    processed_data_dir=CURRENT_DATA_DIR,\n",
    "    indices=best100,\n",
    "    compute_euclidean=True,\n",
    "    center_point_index=2,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    selected_labels=[0, 4],\n",
    "    label_map=[0, 1],\n",
    ")\n",
    "\n",
    "val_dataset = PreprocessedDataset(\n",
    "    'val',\n",
    "    processed_data_dir=CURRENT_DATA_DIR,\n",
    "    indices=best100,\n",
    "    compute_euclidean=True,\n",
    "    center_point_index=2,\n",
    "    max_sequence_length=46,\n",
    "    selected_labels=[0, 4],\n",
    "    label_map=[0, 1],\n",
    ")\n",
    "\n",
    "test_dataset = PreprocessedDataset(\n",
    "    'test',\n",
    "    processed_data_dir=CURRENT_DATA_DIR,\n",
    "    indices=best100,\n",
    "    compute_euclidean=True,\n",
    "    center_point_index=2,\n",
    "    max_sequence_length=46,\n",
    "    selected_labels=[0, 4],\n",
    "    label_map=[0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdb980",
   "metadata": {},
   "source": [
    "tu moze jescze cos do wyswietlenia tych przetworzonych datasetow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)  # (B, T_max, num_features)\n",
    "    break\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "for X, y in val_loader:\n",
    "    print(X.shape, y.shape)  # (B, T_max, num_features)\n",
    "    break\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "for X, y in test_loader:\n",
    "    print(X.shape, y.shape)  # (B, T_max, num_features)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005116a",
   "metadata": {},
   "source": [
    "#### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22143c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequenceModel(NUM_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES, DROPOUT_PROB).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ac644",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315933ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=SCHEDULER_FACTOR,\n",
    "    patience=10,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "model_name = 'testing_new_code_bi_lstm_2_classes.pt'\n",
    "model_filepath = os.path.join(MODEL_SAVE_DIR, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13790d",
   "metadata": {},
   "source": [
    "saprawdzic jak teraz działa ten scheduler !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    model_save_path=model_filepath,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    monitor='val_acc',  # or 'val_loss'\n",
    "    minimize_monitor=False,\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.print_training_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path, best_model_path, history = trainer.fit()\n",
    "print(f\"Final model saved to: {final_model_path}\")\n",
    "if best_model_path:\n",
    "    print(f\"Best model saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824840a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198efc5a",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_filepath, map_location=DEVICE), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model, test_loader, device=DEVICE, model_name=model_name, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, labels, preds = evaluator.evaluate_epoch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
